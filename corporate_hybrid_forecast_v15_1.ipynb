{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e849b4",
   "metadata": {},
   "source": [
    "# Planet | Capacity Forecast v15 (Stability‑First, Auditable)\n",
    "\n",
    "This notebook provides a **clean, minimal, and fully auditable** capacity forecasting pipeline.\n",
    "\n",
    "**Scope**\n",
    "- **Monthly forecast**: 12 months ahead (department-level, allocated from vertical forecasts)\n",
    "- **Daily plan**: 90 days ahead (department-level) using a historical **day-of-week (DOW) profile** (monthly forecast remains untouched)\n",
    "- **Languages**: Only `English, Spanish, Portuguese, French, German, Italian`. Any other language is mapped to **English**.\n",
    "\n",
    "**Modeling strategy (stability-first)**\n",
    "1. Aggregate incoming tickets to **monthly volumes per vertical**\n",
    "2. Forecast each vertical using **ETS (ExponentialSmoothing) only**\n",
    "3. Apply **vertical level recalibration** (last 3 months actual vs fitted)\n",
    "4. Allocate vertical forecast to departments using **EWMA shares** (renormalized per vertical-month)\n",
    "5. Compute **dept accuracy** via a clean rolling backtest (WAPE → Accuracy_staffing_%)\n",
    "\n",
    "Output Excel is saved under `outputs/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b84f898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: C:\\Users\\pt3canro\\Desktop\\CAPACITY\n",
      "INPUT_DIR: C:\\Users\\pt3canro\\Desktop\\CAPACITY\\input_model\n",
      "OUTPUT_DIR: C:\\Users\\pt3canro\\Desktop\\CAPACITY\\outputs\n",
      "Output file: C:\\Users\\pt3canro\\Desktop\\CAPACITY\\outputs\\capacity_forecast_v15.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 0) Setup (interactive folder selector)\n",
    "# -----------------------------\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\pt3canro\\Desktop\\CAPACITY\"\n",
    "BASE_DIR = str(Path(BASE_DIR).expanduser().resolve())\n",
    "\n",
    "INPUT_DIR  = str(Path(BASE_DIR) / \"input_model\")\n",
    "OUTPUT_DIR = str(Path(BASE_DIR) / \"outputs\")\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INCOMING_SOURCE_PATH = os.path.join(INPUT_DIR, \"Incoming_new.xlsx\")  # Sheet 'Main'\n",
    "INCOMING_SHEET = \"Main\"\n",
    "\n",
    "DEPT_MAP_PATH = os.path.join(INPUT_DIR, \"department.xlsx\")\n",
    "DEPT_MAP_SHEET = \"map\"\n",
    "\n",
    "PRODUCTIVITY_PATH = os.path.join(INPUT_DIR, \"productivity_agents.xlsx\")  # optional\n",
    "\n",
    "OUTPUT_XLSX = os.path.join(OUTPUT_DIR, \"capacity_forecast_v15.xlsx\")\n",
    "\n",
    "# Horizons\n",
    "H_MONTHS = 12\n",
    "DAILY_HORIZON_DAYS = 90\n",
    "\n",
    "# Prediction interval\n",
    "PI_ALPHA = 0.05  # 95% PI\n",
    "\n",
    "# Backtest settings\n",
    "BT_MIN_TRAIN_MONTHS = 12\n",
    "BT_EVAL_MONTHS = 9\n",
    "BT_HORIZON_MONTHS = 1\n",
    "BT_MAX_SPLITS = 9\n",
    "\n",
    "# Governance\n",
    "SUPPORTED_LANGUAGES = [\"English\",\"Spanish\",\"Portuguese\",\"French\",\"German\",\"Italian\"]\n",
    "DEFAULT_LANGUAGE = \"English\"\n",
    "\n",
    "CRITICAL_VERTICALS = [\"Payments\",\"Hospitality\",\"Partners\"]  # adjust if needed\n",
    "\n",
    "VERTICAL_LEVEL_ADJ = {\n",
    "    \"enabled\": True,\n",
    "    \"lookback_months\": 3,\n",
    "    \"clip_min\": 0.70,\n",
    "    \"clip_max\": 1.10,\n",
    "}\n",
    "\n",
    "DEPT_SHARE_EWMA_ALPHA = 0.50\n",
    "\n",
    "# DOW profile\n",
    "DOW_LOOKBACK_DAYS = 180\n",
    "DOW_MIN_OBS = 30\n",
    "WEEKEND_OPEN_THRESHOLD = 0.05  # if weekend share < 5%, treat dept as closed weekends for daily plan\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"INPUT_DIR:\", INPUT_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"Output file:\", OUTPUT_XLSX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfa12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Imports\n",
    "# -----------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050d7e9",
   "metadata": {},
   "source": [
    "## 2) Data loaders & standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f1a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_incoming(path: str, sheet: str = \"Main\") -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "    if \"Date\" not in df.columns:\n",
    "        for c in [\"date\", \"created_date\", \"created_at\"]:\n",
    "            if c in df.columns:\n",
    "                df = df.rename(columns={c: \"Date\"})\n",
    "                break\n",
    "    if \"Date\" not in df.columns:\n",
    "        raise ValueError(\"Incoming_new.xlsx must contain a 'Date' column (or a recognizable alternative).\")\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Ticket weight: if absent, each row is 1 ticket\n",
    "    if \"ticket_total\" not in df.columns:\n",
    "        df[\"ticket_total\"] = 1.0\n",
    "    else:\n",
    "        df[\"ticket_total\"] = pd.to_numeric(df[\"ticket_total\"], errors=\"coerce\").fillna(1.0)\n",
    "\n",
    "    for col in [\"department_id\",\"department_name\",\"vertical\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    if \"language\" not in df.columns:\n",
    "        df[\"language\"] = DEFAULT_LANGUAGE\n",
    "    df[\"language\"] = df[\"language\"].fillna(DEFAULT_LANGUAGE).astype(str)\n",
    "    df.loc[~df[\"language\"].isin(SUPPORTED_LANGUAGES), \"language\"] = DEFAULT_LANGUAGE\n",
    "\n",
    "    df[\"department_id\"] = df[\"department_id\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def load_dept_map(path: str, sheet: str = \"map\") -> pd.DataFrame:\n",
    "    m = pd.read_excel(path, sheet_name=sheet)\n",
    "    if \"department_id\" not in m.columns:\n",
    "        raise ValueError(\"department.xlsx must contain 'department_id'\")\n",
    "    m[\"department_id\"] = m[\"department_id\"].astype(str)\n",
    "    if \"vertical\" not in m.columns and \"vertical_name\" in m.columns:\n",
    "        m = m.rename(columns={\"vertical_name\":\"vertical\"})\n",
    "    return m\n",
    "\n",
    "def load_productivity(path: str) -> pd.DataFrame:\n",
    "    p = pd.read_excel(path)\n",
    "    if \"Date\" not in p.columns:\n",
    "        raise ValueError(\"productivity_agents.xlsx must contain 'Date'\")\n",
    "    p[\"Date\"] = pd.to_datetime(p[\"Date\"])\n",
    "    if \"prod_total_model\" in p.columns:\n",
    "        p[\"prod_total_model\"] = pd.to_numeric(p[\"prod_total_model\"], errors=\"coerce\").fillna(0.0)\n",
    "    else:\n",
    "        p[\"prod_total_model\"] = 0.0\n",
    "    for col in [\"department_id\",\"department_name\"]:\n",
    "        if col not in p.columns:\n",
    "            p[col] = np.nan\n",
    "    p[\"department_id\"] = p[\"department_id\"].astype(str)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8060f60",
   "metadata": {},
   "source": [
    "## 3) Monthly aggregates & shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088a375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_vertical_series(incoming: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = incoming.copy()\n",
    "    d[\"month\"] = d[\"Date\"].dt.to_period(\"M\")\n",
    "    vm = d.groupby([\"vertical\",\"month\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    return vm.sort_values([\"vertical\",\"month\"])\n",
    "\n",
    "def monthly_dept_series(incoming: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = incoming.copy()\n",
    "    d[\"month\"] = d[\"Date\"].dt.to_period(\"M\")\n",
    "    dm = d.groupby([\"vertical\",\"department_id\",\"month\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    return dm.sort_values([\"vertical\",\"department_id\",\"month\"])\n",
    "\n",
    "def dept_share_ewma_within_vertical(incoming: pd.DataFrame, alpha: float = 0.5) -> pd.DataFrame:\n",
    "    dm = monthly_dept_series(incoming)\n",
    "    vm = monthly_vertical_series(incoming).rename(columns={\"ticket_total\":\"vertical_total\"})\n",
    "    x = dm.merge(vm, on=[\"vertical\",\"month\"], how=\"left\")\n",
    "    x[\"share\"] = np.where(x[\"vertical_total\"]>0, x[\"ticket_total\"]/x[\"vertical_total\"], 0.0)\n",
    "    x = x.sort_values([\"vertical\",\"department_id\",\"month\"])\n",
    "\n",
    "    x[\"share_ewma\"] = x.groupby([\"vertical\",\"department_id\"])[\"share\"].transform(\n",
    "        lambda s: s.ewm(alpha=alpha, adjust=False).mean()\n",
    "    )\n",
    "    denom = x.groupby([\"vertical\",\"month\"])[\"share_ewma\"].transform(\"sum\")\n",
    "    x[\"share_final\"] = np.where(denom>0, x[\"share_ewma\"]/denom, 0.0)\n",
    "\n",
    "    return x[[\"vertical\",\"department_id\",\"month\",\"share_final\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea367977",
   "metadata": {},
   "source": [
    "## 4) Vertical forecasting (ETS-only) + Level recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397ddc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ets_monthly(y_ts: pd.Series):\n",
    "    y_ts = pd.Series(y_ts).dropna().astype(float).sort_index()\n",
    "    if len(y_ts) < 6:\n",
    "        return None, float(y_ts.std()) if len(y_ts) else 0.0\n",
    "\n",
    "    try:\n",
    "        seasonal = \"add\" if len(y_ts) >= 24 else None\n",
    "        sp = 12 if seasonal else None\n",
    "        model = ExponentialSmoothing(\n",
    "            y_ts,\n",
    "            trend=\"add\",\n",
    "            seasonal=seasonal,\n",
    "            seasonal_periods=sp,\n",
    "            initialization_method=\"estimated\"\n",
    "        )\n",
    "        fit = model.fit(optimized=True)\n",
    "        resid = (y_ts - fit.fittedvalues).dropna()\n",
    "        sigma = float(resid.std()) if len(resid) else float(y_ts.std())\n",
    "        return fit, sigma\n",
    "    except Exception:\n",
    "        return None, float(y_ts.std()) if len(y_ts) else 0.0\n",
    "\n",
    "def forecast_vertical_final(incoming: pd.DataFrame, periods: int = 12, alpha: float = 0.05) -> pd.DataFrame:\n",
    "    vm = monthly_vertical_series(incoming)\n",
    "    rows = []\n",
    "\n",
    "    lookback = int(VERTICAL_LEVEL_ADJ[\"lookback_months\"])\n",
    "    clip_min = float(VERTICAL_LEVEL_ADJ[\"clip_min\"])\n",
    "    clip_max = float(VERTICAL_LEVEL_ADJ[\"clip_max\"])\n",
    "    enabled = bool(VERTICAL_LEVEL_ADJ[\"enabled\"])\n",
    "    z = 1.96  # ~95%\n",
    "\n",
    "    for v, g in vm.groupby(\"vertical\"):\n",
    "        y = g.set_index(\"month\")[\"ticket_total\"].sort_index()\n",
    "        y_ts = y.copy()\n",
    "        y_ts.index = y_ts.index.to_timestamp()\n",
    "\n",
    "        fit, sigma = fit_ets_monthly(y_ts)\n",
    "\n",
    "        last_m = y.index.max()\n",
    "        future_m = pd.period_range(last_m + 1, periods=periods, freq=\"M\")\n",
    "        future_idx = future_m.to_timestamp()\n",
    "\n",
    "        if fit is None:\n",
    "            last = float(y.iloc[-1]) if len(y) else 0.0\n",
    "            fc = pd.Series([last]*periods, index=future_idx)\n",
    "            fitted = pd.Series([last]*len(y_ts), index=y_ts.index)\n",
    "        else:\n",
    "            fc_vals = fit.forecast(periods)\n",
    "            fc = pd.Series(fc_vals.values, index=future_idx)\n",
    "            fitted = fit.fittedvalues\n",
    "\n",
    "        fc = fc.clip(lower=0.0)\n",
    "        p05 = (fc - z*sigma).clip(lower=0.0)\n",
    "        p95 = (fc + z*sigma).clip(lower=0.0)\n",
    "\n",
    "        factor = 1.0\n",
    "        if enabled and (v in CRITICAL_VERTICALS) and len(y_ts) >= lookback:\n",
    "            actual_last = float(y_ts.tail(lookback).mean())\n",
    "            fitted_last = float(fitted.tail(lookback).mean()) if len(fitted) else actual_last\n",
    "            if fitted_last > 0:\n",
    "                factor = float(np.clip(actual_last / fitted_last, clip_min, clip_max))\n",
    "\n",
    "        rows.append(pd.DataFrame({\n",
    "            \"vertical\": v,\n",
    "            \"month\": future_m,\n",
    "            \"forecast_monthly_vertical\": (fc*factor).values,\n",
    "            \"forecast_p05_vertical\": (p05*factor).values,\n",
    "            \"forecast_p95_vertical\": (p95*factor).values,\n",
    "            \"vertical_level_factor\": factor,\n",
    "            \"model_used\": \"ETS\"\n",
    "        }))\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35c175",
   "metadata": {},
   "source": [
    "## 5) Allocation to department (EWMA shares, renormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef08e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_vertical_to_dept(fc_vertical: pd.DataFrame, shares_vd: pd.DataFrame) -> pd.DataFrame:\n",
    "    last_share = shares_vd.sort_values(\"month\").groupby([\"vertical\",\"department_id\"]).tail(1)\n",
    "    last_share = last_share[[\"vertical\",\"department_id\",\"share_final\"]].rename(columns={\"share_final\":\"share_cf\"})\n",
    "\n",
    "    fc = fc_vertical.copy()\n",
    "    fc = fc.merge(last_share, on=\"vertical\", how=\"left\")  # expands to depts per vertical\n",
    "    fc[\"share_cf\"] = fc[\"share_cf\"].fillna(0.0)\n",
    "\n",
    "    out = fc.assign(\n",
    "        forecast_monthly_dept = fc[\"forecast_monthly_vertical\"] * fc[\"share_cf\"],\n",
    "        forecast_p05_dept     = fc[\"forecast_p05_vertical\"]     * fc[\"share_cf\"],\n",
    "        forecast_p95_dept     = fc[\"forecast_p95_vertical\"]     * fc[\"share_cf\"],\n",
    "    )\n",
    "    return out[[\"vertical\",\"department_id\",\"month\",\n",
    "                \"forecast_monthly_dept\",\"forecast_p05_dept\",\"forecast_p95_dept\",\n",
    "                \"vertical_level_factor\",\"model_used\",\"share_cf\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7b63b",
   "metadata": {},
   "source": [
    "## 6) Daily plan (90d) using DOW profile (monthly remains untouched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a19fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dept_dow_profile(incoming: pd.DataFrame, lookback_days: int = 180, min_obs: int = 30) -> pd.DataFrame:\n",
    "    d = incoming.copy()\n",
    "    d = d[d[\"Date\"] >= (d[\"Date\"].max() - pd.Timedelta(days=lookback_days))]\n",
    "    daily = d.groupby([\"department_id\",\"Date\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    daily[\"dow\"] = pd.to_datetime(daily[\"Date\"]).dt.dayofweek\n",
    "\n",
    "    prof = daily.groupby([\"department_id\",\"dow\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    tot = prof.groupby(\"department_id\")[\"ticket_total\"].transform(\"sum\")\n",
    "    prof[\"dow_share\"] = np.where(tot>0, prof[\"ticket_total\"]/tot, 0.0)\n",
    "\n",
    "    idx = pd.MultiIndex.from_product([prof[\"department_id\"].unique(), range(7)], names=[\"department_id\",\"dow\"])\n",
    "    prof = prof.set_index([\"department_id\",\"dow\"]).reindex(idx).reset_index()\n",
    "    prof[\"dow_share\"] = prof[\"dow_share\"].fillna(0.0)\n",
    "\n",
    "    obs = daily.groupby(\"department_id\")[\"Date\"].nunique().rename(\"n_days\").reset_index()\n",
    "    prof = prof.merge(obs, on=\"department_id\", how=\"left\")\n",
    "\n",
    "    def _fix(g):\n",
    "        if float(g[\"n_days\"].iloc[0] or 0) < min_obs:\n",
    "            g[\"dow_share\"] = 0.0\n",
    "            g.loc[g[\"dow\"].isin([0,1,2,3,4]), \"dow_share\"] = 0.2\n",
    "        else:\n",
    "            s = g[\"dow_share\"].sum()\n",
    "            if s > 0:\n",
    "                g[\"dow_share\"] = g[\"dow_share\"] / s\n",
    "        return g\n",
    "\n",
    "    prof = prof.groupby(\"department_id\", group_keys=False).apply(_fix)\n",
    "    return prof[[\"department_id\",\"dow\",\"dow_share\"]]\n",
    "\n",
    "def daily_plan_from_monthly(fc_dept_monthly: pd.DataFrame, dow_profile: pd.DataFrame,\n",
    "                            start_date: Optional[pd.Timestamp] = None, horizon_days: int = 90) -> pd.DataFrame:\n",
    "    if start_date is None:\n",
    "        start_date = pd.Timestamp.today().normalize()\n",
    "\n",
    "    end_date = start_date + pd.Timedelta(days=horizon_days-1)\n",
    "    days = pd.date_range(start_date, end_date, freq=\"D\")\n",
    "\n",
    "    day_df = pd.DataFrame({\"Date\": days})\n",
    "    day_df[\"month\"] = day_df[\"Date\"].dt.to_period(\"M\")\n",
    "    day_df[\"dow\"] = day_df[\"Date\"].dt.dayofweek\n",
    "\n",
    "    m = fc_dept_monthly.copy()\n",
    "    out = m.merge(day_df, on=\"month\", how=\"right\")\n",
    "    out[\"department_id\"] = out[\"department_id\"].astype(str)\n",
    "\n",
    "    out = out.merge(dow_profile, on=[\"department_id\",\"dow\"], how=\"left\")\n",
    "    out[\"dow_share\"] = out[\"dow_share\"].fillna(0.0)\n",
    "\n",
    "    wk = dow_profile.copy()\n",
    "    wk[\"is_weekend\"] = wk[\"dow\"].isin([5,6])\n",
    "    wk_sum = wk.groupby(\"department_id\").apply(lambda g: float(g.loc[g[\"is_weekend\"],\"dow_share\"].sum())).rename(\"weekend_share\").reset_index()\n",
    "    out = out.merge(wk_sum, on=\"department_id\", how=\"left\")\n",
    "    out[\"weekend_share\"] = out[\"weekend_share\"].fillna(0.0)\n",
    "\n",
    "    closed = out[\"weekend_share\"] < WEEKEND_OPEN_THRESHOLD\n",
    "    out.loc[closed & out[\"dow\"].isin([5,6]), \"dow_share\"] = 0.0\n",
    "\n",
    "    denom = out.groupby([\"department_id\",\"month\"])[\"dow_share\"].transform(\"sum\")\n",
    "    out[\"dow_share_adj\"] = np.where(denom>0, out[\"dow_share\"]/denom, 0.0)\n",
    "\n",
    "    out[\"forecast_daily_dept\"] = out[\"forecast_monthly_dept\"] * out[\"dow_share_adj\"]\n",
    "    out[\"p05_daily_dept\"]      = out[\"forecast_p05_dept\"]     * out[\"dow_share_adj\"]\n",
    "    out[\"p95_daily_dept\"]      = out[\"forecast_p95_dept\"]     * out[\"dow_share_adj\"]\n",
    "\n",
    "    return out[[\"Date\",\"vertical\",\"department_id\",\"month\",\"dow\",\n",
    "                \"forecast_daily_dept\",\"p05_daily_dept\",\"p95_daily_dept\",\n",
    "                \"forecast_monthly_dept\",\"forecast_p05_dept\",\"forecast_p95_dept\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10bc674",
   "metadata": {},
   "source": [
    "## 7) Backtest (clean, same pipeline, WAPE → Accuracy_staffing_%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0027c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wape(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "    y_true = pd.Series(y_true).astype(float)\n",
    "    y_pred = pd.Series(y_pred).astype(float)\n",
    "    denom = float(y_true.sum())\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return float(np.abs(y_true - y_pred).sum() / denom)\n",
    "\n",
    "def backtest_dept_accuracy(\n",
    "    incoming: pd.DataFrame,\n",
    "    min_train_months: int = 12,\n",
    "    eval_months: int = 9,\n",
    "    horizon_months: int = 1,\n",
    "    max_splits: int = 9,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    inc = incoming.copy()\n",
    "    inc[\"Date\"] = pd.to_datetime(inc[\"Date\"], errors=\"coerce\")\n",
    "    inc = inc.dropna(subset=[\"Date\"])\n",
    "    inc[\"month\"] = inc[\"Date\"].dt.to_period(\"M\")\n",
    "\n",
    "    all_months = sorted(inc[\"month\"].unique())\n",
    "    if len(all_months) < (min_train_months + horizon_months + 1):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    eval_targets = all_months[-eval_months:]\n",
    "    splits = eval_targets[-max_splits:]\n",
    "    results = []\n",
    "\n",
    "    # cache dept->vertical\n",
    "    dept_vertical = None\n",
    "    if \"vertical\" in inc.columns:\n",
    "        dept_vertical = (\n",
    "            inc[[\"department_id\", \"vertical\"]]\n",
    "            .drop_duplicates(\"department_id\")\n",
    "            .copy()\n",
    "        )\n",
    "\n",
    "    for target_month in splits:\n",
    "\n",
    "        train_end = target_month - horizon_months\n",
    "        train = inc[inc[\"month\"] <= train_end].copy()\n",
    "        test = inc[inc[\"month\"] == target_month].copy()\n",
    "\n",
    "        if train[\"month\"].nunique() < min_train_months:\n",
    "            continue\n",
    "\n",
    "        shares_vd = dept_share_ewma_within_vertical(\n",
    "            train, alpha=DEPT_SHARE_EWMA_ALPHA\n",
    "        )\n",
    "\n",
    "        fc_vert = forecast_vertical_final(\n",
    "            train, periods=horizon_months, alpha=PI_ALPHA\n",
    "        ).copy()\n",
    "\n",
    "        if not pd.api.types.is_period_dtype(fc_vert[\"month\"]):\n",
    "            fc_vert[\"month\"] = pd.to_datetime(fc_vert[\"month\"]).dt.to_period(\"M\")\n",
    "\n",
    "        fc_vert = fc_vert[fc_vert[\"month\"] == target_month]\n",
    "        if fc_vert.empty:\n",
    "            continue\n",
    "\n",
    "        fc_dept = allocate_vertical_to_dept(fc_vert, shares_vd)\n",
    "\n",
    "        # Ensure vertical in fc_dept\n",
    "        if \"vertical\" not in fc_dept.columns:\n",
    "            if \"vertical\" in shares_vd.columns:\n",
    "                vd = shares_vd[[\"department_id\", \"vertical\"]].drop_duplicates()\n",
    "                fc_dept = fc_dept.merge(vd, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        if \"vertical\" not in fc_dept.columns and dept_vertical is not None:\n",
    "            fc_dept = fc_dept.merge(dept_vertical, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        if \"vertical\" not in fc_dept.columns:\n",
    "            fc_dept[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "        fc_dept[\"vertical\"] = (\n",
    "            fc_dept[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "        )\n",
    "\n",
    "        # Ensure vertical in test\n",
    "        if \"vertical\" not in test.columns and dept_vertical is not None:\n",
    "            test = test.merge(dept_vertical, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        if \"vertical\" not in test.columns:\n",
    "            test[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "        test[\"vertical\"] = test[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "        actual = (\n",
    "            test.groupby([\"vertical\", \"department_id\"], as_index=False)[\n",
    "                \"ticket_total\"\n",
    "            ]\n",
    "            .sum()\n",
    "            .rename(columns={\"ticket_total\": \"actual\"})\n",
    "        )\n",
    "\n",
    "        pred = (\n",
    "            fc_dept.groupby([\"vertical\", \"department_id\"], as_index=False)[\n",
    "                \"forecast_monthly_dept\"\n",
    "            ]\n",
    "            .sum()\n",
    "            .rename(columns={\"forecast_monthly_dept\": \"forecast\"})\n",
    "        )\n",
    "\n",
    "        m = actual.merge(\n",
    "            pred, on=[\"vertical\", \"department_id\"], how=\"outer\"\n",
    "        ).fillna(0.0)\n",
    "\n",
    "        m[\"month\"] = target_month\n",
    "        results.append(m)\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    bt = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    def _metrics(g: pd.DataFrame) -> pd.Series:\n",
    "        y = g[\"actual\"].values.astype(float)\n",
    "        yhat = g[\"forecast\"].values.astype(float)\n",
    "\n",
    "        mae = float(np.mean(np.abs(y - yhat)))\n",
    "        bias = (\n",
    "            float((yhat.sum() - y.sum()) / y.sum() * 100)\n",
    "            if y.sum() > 0\n",
    "            else np.nan\n",
    "        )\n",
    "        wape = (\n",
    "            compute_wape(y, yhat) * 100\n",
    "            if y.sum() > 0\n",
    "            else np.nan\n",
    "        )\n",
    "        acc = (\n",
    "            max(0.0, 100.0 - wape)\n",
    "            if np.isfinite(wape)\n",
    "            else np.nan\n",
    "        )\n",
    "\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"MAE\": mae,\n",
    "                \"Bias_%\": bias,\n",
    "                \"WAPE_%\": wape,\n",
    "                \"Accuracy_staffing_%\": acc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    out = (\n",
    "        bt.groupby([\"vertical\", \"department_id\"])\n",
    "        .apply(_metrics)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    out[\"Eval_Months\"] = (\n",
    "        bt.groupby([\"vertical\", \"department_id\"])[\"month\"]\n",
    "        .nunique()\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a68e7",
   "metadata": {},
   "source": [
    "## 8) Run end-to-end pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966ada6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming rows: 478923\n",
      "Verticals: ['Hospitality', 'Partners', 'Payments']\n",
      "Departments: 21\n",
      "Share sum (min/max): 0.9999999999999999 1.0000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:903: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vertical factors (sanity):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pt3canro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertical</th>\n",
       "      <th>vertical_level_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>0.833870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Payments</td>\n",
       "      <td>0.856383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Partners</td>\n",
       "      <td>1.031163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      vertical  vertical_level_factor\n",
       "0  Hospitality               0.833870\n",
       "2     Payments               0.856383\n",
       "1     Partners               1.031163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy table (top 15 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertical</th>\n",
       "      <th>department_id</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Bias_%</th>\n",
       "      <th>WAPE_%</th>\n",
       "      <th>Accuracy_staffing_%</th>\n",
       "      <th>Eval_Months</th>\n",
       "      <th>department_name</th>\n",
       "      <th>department_group</th>\n",
       "      <th>team_hierarchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>10</td>\n",
       "      <td>143.645609</td>\n",
       "      <td>20.133689</td>\n",
       "      <td>25.156849</td>\n",
       "      <td>74.843151</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_PREM_L2</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>11</td>\n",
       "      <td>123.691947</td>\n",
       "      <td>27.222585</td>\n",
       "      <td>37.169533</td>\n",
       "      <td>62.830467</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_CLOUD_L2</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>23</td>\n",
       "      <td>149.121024</td>\n",
       "      <td>10.925390</td>\n",
       "      <td>23.620014</td>\n",
       "      <td>76.379986</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_FRANCE</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>4</td>\n",
       "      <td>89.714356</td>\n",
       "      <td>4249.627394</td>\n",
       "      <td>4249.627394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_DIST</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>44</td>\n",
       "      <td>1.331229</td>\n",
       "      <td>1198.106173</td>\n",
       "      <td>1198.106173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_PROJ</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>5</td>\n",
       "      <td>255.764087</td>\n",
       "      <td>18.269768</td>\n",
       "      <td>20.108996</td>\n",
       "      <td>79.891004</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_INTEG</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>6</td>\n",
       "      <td>125.355426</td>\n",
       "      <td>7.761858</td>\n",
       "      <td>127.913700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_KEY</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>7</td>\n",
       "      <td>249.307922</td>\n",
       "      <td>5.879805</td>\n",
       "      <td>17.370684</td>\n",
       "      <td>82.629316</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSH_L1</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Hoist PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>8</td>\n",
       "      <td>132.800738</td>\n",
       "      <td>14.117133</td>\n",
       "      <td>19.619282</td>\n",
       "      <td>80.380718</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_CLOUD_L1</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>9</td>\n",
       "      <td>165.429111</td>\n",
       "      <td>8.934268</td>\n",
       "      <td>12.553643</td>\n",
       "      <td>87.446357</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_PREM_L1</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Partners</td>\n",
       "      <td>12</td>\n",
       "      <td>125.833575</td>\n",
       "      <td>3.080219</td>\n",
       "      <td>30.353851</td>\n",
       "      <td>69.646149</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PART_APAC</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Partners</td>\n",
       "      <td>13</td>\n",
       "      <td>182.160790</td>\n",
       "      <td>7.643983</td>\n",
       "      <td>46.168603</td>\n",
       "      <td>53.831397</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PART_EMEA</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Partners</td>\n",
       "      <td>14</td>\n",
       "      <td>71.979743</td>\n",
       "      <td>-0.552694</td>\n",
       "      <td>34.203680</td>\n",
       "      <td>65.796320</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PART_LATAM</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Partners</td>\n",
       "      <td>15</td>\n",
       "      <td>109.012635</td>\n",
       "      <td>19.001162</td>\n",
       "      <td>75.528384</td>\n",
       "      <td>24.471616</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PART_US</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Partners</td>\n",
       "      <td>16</td>\n",
       "      <td>18.525108</td>\n",
       "      <td>-12.951745</td>\n",
       "      <td>33.278638</td>\n",
       "      <td>66.721362</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PXCS</td>\n",
       "      <td>Proximis</td>\n",
       "      <td>Proximis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vertical department_id         MAE       Bias_%       WAPE_%  \\\n",
       "0   Hospitality            10  143.645609    20.133689    25.156849   \n",
       "1   Hospitality            11  123.691947    27.222585    37.169533   \n",
       "2   Hospitality            23  149.121024    10.925390    23.620014   \n",
       "3   Hospitality             4   89.714356  4249.627394  4249.627394   \n",
       "4   Hospitality            44    1.331229  1198.106173  1198.106173   \n",
       "5   Hospitality             5  255.764087    18.269768    20.108996   \n",
       "6   Hospitality             6  125.355426     7.761858   127.913700   \n",
       "7   Hospitality             7  249.307922     5.879805    17.370684   \n",
       "8   Hospitality             8  132.800738    14.117133    19.619282   \n",
       "9   Hospitality             9  165.429111     8.934268    12.553643   \n",
       "10     Partners            12  125.833575     3.080219    30.353851   \n",
       "11     Partners            13  182.160790     7.643983    46.168603   \n",
       "12     Partners            14   71.979743    -0.552694    34.203680   \n",
       "13     Partners            15  109.012635    19.001162    75.528384   \n",
       "14     Partners            16   18.525108   -12.951745    33.278638   \n",
       "\n",
       "    Accuracy_staffing_%  Eval_Months   department_name  \\\n",
       "0             74.843151            9   CS_PMSP_PREM_L2   \n",
       "1             62.830467            9  CS_PMSP_CLOUD_L2   \n",
       "2             76.379986            9    CS_PMSP_FRANCE   \n",
       "3              0.000000            9      CS_PMSP_DIST   \n",
       "4              0.000000            9      CS_PMSP_PROJ   \n",
       "5             79.891004            9     CS_PMSP_INTEG   \n",
       "6              0.000000            9       CS_PMSP_KEY   \n",
       "7             82.629316            9        CS_PMSH_L1   \n",
       "8             80.380718            9  CS_PMSP_CLOUD_L1   \n",
       "9             87.446357            9   CS_PMSP_PREM_L1   \n",
       "10            69.646149            9      CS_PART_APAC   \n",
       "11            53.831397            9      CS_PART_EMEA   \n",
       "12            65.796320            9     CS_PART_LATAM   \n",
       "13            24.471616            9        CS_PART_US   \n",
       "14            66.721362            9           CS_PXCS   \n",
       "\n",
       "            department_group team_hierarchy  \n",
       "0   Planet Hospitality - PMS     Protel PMS  \n",
       "1   Planet Hospitality - PMS     Protel PMS  \n",
       "2   Planet Hospitality - PMS     Protel PMS  \n",
       "3   Planet Hospitality - PMS     Protel PMS  \n",
       "4    Planet Partners Support     Protel PMS  \n",
       "5   Planet Hospitality - PMS     Protel PMS  \n",
       "6   Planet Hospitality - PMS     Protel PMS  \n",
       "7   Planet Hospitality - PMS      Hoist PMS  \n",
       "8   Planet Hospitality - PMS     Protel PMS  \n",
       "9   Planet Hospitality - PMS     Protel PMS  \n",
       "10   Planet Partners Support       Partners  \n",
       "11   Planet Partners Support       Partners  \n",
       "12   Planet Partners Support       Partners  \n",
       "13   Planet Partners Support       Partners  \n",
       "14                  Proximis       Proximis  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "incoming = load_incoming(INCOMING_SOURCE_PATH, INCOMING_SHEET)\n",
    "mapping = load_dept_map(DEPT_MAP_PATH, DEPT_MAP_SHEET)\n",
    "\n",
    "incoming = incoming.merge(mapping, on=\"department_id\", how=\"left\", suffixes=(\"\",\"_map\"))\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# SAFE COALESCE: vertical + department_name (v15.1)\n",
    "# Guarantees columns exist and prevents KeyError: 'vertical'\n",
    "# -----------------------------\n",
    "if \"vertical\" not in incoming.columns:\n",
    "    incoming[\"vertical\"] = pd.NA\n",
    "if \"department_name\" not in incoming.columns:\n",
    "    incoming[\"department_name\"] = pd.NA\n",
    "\n",
    "if \"vertical_map\" in incoming.columns:\n",
    "    incoming[\"vertical\"] = incoming[\"vertical_map\"].combine_first(incoming[\"vertical\"])\n",
    "if \"department_name_map\" in incoming.columns:\n",
    "    incoming[\"department_name\"] = incoming[\"department_name_map\"].combine_first(incoming[\"department_name\"])\n",
    "\n",
    "incoming[\"vertical\"] = incoming[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "incoming[\"department_name\"] = incoming[\"department_name\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "if \"vertical_map\" in incoming.columns:\n",
    "    incoming[\"vertical\"] = incoming[\"vertical_map\"].combine_first(incoming[\"vertical\"])\n",
    "if \"department_name_map\" in incoming.columns:\n",
    "    incoming[\"department_name\"] = incoming[\"department_name_map\"].combine_first(incoming[\"department_name\"])\n",
    "\n",
    "incoming[\"vertical\"] = incoming[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "incoming[\"department_name\"] = incoming[\"department_name\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "print(\"Incoming rows:\", len(incoming))\n",
    "print(\"Verticals:\", sorted(incoming[\"vertical\"].unique().tolist()))\n",
    "print(\"Departments:\", incoming[\"department_id\"].nunique())\n",
    "\n",
    "# Shares\n",
    "shares_vd = dept_share_ewma_within_vertical(incoming, alpha=DEPT_SHARE_EWMA_ALPHA)\n",
    "san = shares_vd.groupby([\"vertical\",\"month\"])[\"share_final\"].sum().reset_index(name=\"share_sum\")\n",
    "print(\"Share sum (min/max):\", float(san[\"share_sum\"].min()), float(san[\"share_sum\"].max()))\n",
    "\n",
    "# Forecasts\n",
    "fc_vertical = forecast_vertical_final(incoming, periods=H_MONTHS, alpha=PI_ALPHA)\n",
    "fc_dept = allocate_vertical_to_dept(fc_vertical, shares_vd).merge(mapping, on=\"department_id\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# v15.1 GUARDAESPALDAS: fc_dept SIEMPRE con 'vertical'\n",
    "# -----------------------------\n",
    "if \"vertical\" not in fc_dept.columns:\n",
    "    # 1) Preferencia: traértelo desde shares_vd (vertical-dept real del share)\n",
    "    if \"vertical\" in shares_vd.columns:\n",
    "        vd = shares_vd[[\"department_id\", \"vertical\"]].drop_duplicates(\"department_id\")\n",
    "        fc_dept = fc_dept.merge(vd, on=\"department_id\", how=\"left\")\n",
    "\n",
    "# 2) Si aún no está, fallback a mapping\n",
    "if \"vertical\" not in fc_dept.columns:\n",
    "    if \"vertical\" in mapping.columns:\n",
    "        fc_dept = fc_dept.merge(\n",
    "            mapping[[\"department_id\", \"vertical\"]],\n",
    "            on=\"department_id\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_map\")\n",
    "        )\n",
    "\n",
    "# 3) Normaliza nombre si quedó como vertical_map\n",
    "if \"vertical\" not in fc_dept.columns and \"vertical_map\" in fc_dept.columns:\n",
    "    fc_dept[\"vertical\"] = fc_dept[\"vertical_map\"]\n",
    "\n",
    "# 4) Último recurso\n",
    "if \"vertical\" not in fc_dept.columns:\n",
    "    fc_dept[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "fc_dept[\"vertical\"] = fc_dept[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Daily plan\n",
    "dow_profile = compute_dept_dow_profile(incoming, lookback_days=DOW_LOOKBACK_DAYS, min_obs=DOW_MIN_OBS)\n",
    "needed = [\"vertical\",\"department_id\",\"month\",\"forecast_monthly_dept\",\"forecast_p05_dept\",\"forecast_p95_dept\"]\n",
    "missing = [c for c in needed if c not in fc_dept.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"fc_dept missing columns for daily plan: {missing}. Columns={list(fc_dept.columns)}\")\n",
    "\n",
    "daily_plan = daily_plan_from_monthly(\n",
    "    fc_dept_monthly=fc_dept[needed],\n",
    "    dow_profile=dow_profile,\n",
    "    start_date=pd.Timestamp.today().normalize(),\n",
    "    horizon_days=DAILY_HORIZON_DAYS\n",
    ").merge(mapping, on=\"department_id\", how=\"left\")\n",
    "\n",
    "\n",
    "# --- v15.1: asegurar vertical en daily_plan ---\n",
    "if \"vertical\" not in daily_plan.columns:\n",
    "    if \"vertical\" in fc_dept.columns:\n",
    "        daily_plan = daily_plan.merge(\n",
    "            fc_dept[[\"department_id\", \"vertical\"]].drop_duplicates(\"department_id\"),\n",
    "            on=\"department_id\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "    elif \"vertical\" in mapping.columns:\n",
    "        daily_plan = daily_plan.merge(\n",
    "            mapping[[\"department_id\", \"vertical\"]],\n",
    "            on=\"department_id\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_map\"),\n",
    "        )\n",
    "        if \"vertical_map\" in daily_plan.columns:\n",
    "            daily_plan[\"vertical\"] = daily_plan.get(\"vertical\").fillna(daily_plan[\"vertical_map\"])\n",
    "\n",
    "if \"vertical\" not in daily_plan.columns:\n",
    "    daily_plan[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "daily_plan[\"vertical\"] = daily_plan[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Backtest\n",
    "acc_dept = backtest_dept_accuracy(\n",
    "    incoming,\n",
    "    min_train_months=BT_MIN_TRAIN_MONTHS,\n",
    "    eval_months=BT_EVAL_MONTHS,\n",
    "    horizon_months=BT_HORIZON_MONTHS,\n",
    "    max_splits=BT_MAX_SPLITS\n",
    ")\n",
    "\n",
    "# Merge mapping (keep dept metadata) without breaking vertical\n",
    "acc_dept = acc_dept.merge(mapping, on=\"department_id\", how=\"left\", suffixes=(\"\", \"_map\"))\n",
    "\n",
    "# Consolidate vertical if merge created duplicates\n",
    "if \"vertical\" not in acc_dept.columns:\n",
    "    if \"vertical_x\" in acc_dept.columns or \"vertical_y\" in acc_dept.columns:\n",
    "        vx = acc_dept[\"vertical_x\"] if \"vertical_x\" in acc_dept.columns else pd.Series([pd.NA]*len(acc_dept))\n",
    "        vy = acc_dept[\"vertical_y\"] if \"vertical_y\" in acc_dept.columns else pd.Series([pd.NA]*len(acc_dept))\n",
    "        acc_dept[\"vertical\"] = vx.fillna(vy)\n",
    "    elif \"vertical_map\" in acc_dept.columns:\n",
    "        acc_dept[\"vertical\"] = acc_dept[\"vertical_map\"]\n",
    "\n",
    "if \"vertical\" not in acc_dept.columns:\n",
    "    acc_dept[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "acc_dept[\"vertical\"] = acc_dept[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Clean duplicates if present\n",
    "drop_cols = [c for c in [\"vertical_x\", \"vertical_y\", \"vertical_map\"] if c in acc_dept.columns]\n",
    "if drop_cols:\n",
    "    acc_dept = acc_dept.drop(columns=drop_cols)\n",
    "\n",
    "acc_dept = acc_dept.sort_values([\"vertical\", \"department_id\"]) if not acc_dept.empty else acc_dept\n",
    "\n",
    "print(\"\\nVertical factors (sanity):\")\n",
    "display(fc_vertical.groupby(\"vertical\", as_index=False)[\"vertical_level_factor\"].mean().sort_values(\"vertical_level_factor\"))\n",
    "\n",
    "print(\"\\nAccuracy table (top 15 rows):\")\n",
    "display(acc_dept.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b0939",
   "metadata": {},
   "source": [
    "## 9) Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20a56bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\pt3canro\\Desktop\\CAPACITY\\outputs\\capacity_forecast_v15.xlsx\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\") as w:\n",
    "    fc_vertical.sort_values([\"vertical\",\"month\"]).to_excel(w, \"forecast_vertical_monthly\", index=False)\n",
    "    fc_dept.sort_values([\"vertical\",\"department_id\",\"month\"]).to_excel(w, \"forecast_dept_monthly\", index=False)\n",
    "    daily_plan.sort_values([\"vertical\",\"department_id\",\"Date\"]).to_excel(w, \"daily_plan_90d\", index=False)\n",
    "    shares_vd.sort_values([\"vertical\",\"department_id\",\"month\"]).to_excel(w, \"dept_share_ewma\", index=False)\n",
    "    dow_profile.sort_values([\"department_id\",\"dow\"]).to_excel(w, \"dept_dow_profile\", index=False)\n",
    "    acc_dept.sort_values([\"vertical\",\"department_id\"]).to_excel(w, \"accuracy_dept_monthly\", index=False)\n",
    "\n",
    "print(\"Saved:\", OUTPUT_XLSX)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
